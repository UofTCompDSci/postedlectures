{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b493335",
   "metadata": {},
   "source": [
    "## Week 11 - Spatial Data Analysis 2\n",
    "\n",
    "### Overview of Class\n",
    "- Review of last week \n",
    "    - Loading in spatial data\n",
    "    - Joining geodataframes with data tables\n",
    "    - Plotting maps\n",
    "\n",
    "- More on Cartography\n",
    "    - Using different classification schemes\n",
    "    - Adding backgrounds\n",
    "\n",
    "- Clustering\n",
    "    - What is 'clustering'?\n",
    "    - How can we conceptualize clustering in space?\n",
    "        - Spatial autocorrelation\n",
    "\n",
    "- Measuring spatial autocorrelation\n",
    "    - Global measures\n",
    "    - Local measures\n",
    "    - Using `pysal` and `splot`\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e8f047",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's install and then load libraries\n",
    "%pip install geopandas\n",
    "%pip install mapclassify\n",
    "%pip install contextily\n",
    "%pip install libpysal\n",
    "%pip install esda\n",
    "%pip install splot\n",
    "%pip install xlrd\n",
    "%pip install numba==0.53 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcff176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import mapclassify\n",
    "import esda\n",
    "import splot\n",
    "import libpysal as lps\n",
    "import contextily as cx\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebb114c",
   "metadata": {},
   "source": [
    "### Let's bring in the same files we worked with last week to get the ball rolling...\n",
    "\n",
    "We'll be working with the Toronto Neighbourhoods spatial data and the health data today:\n",
    "`Toronto_Neighbourhoods.geojson` and `1_ahd_neighb_db_ast_hbp_mhv_copd_2007.xls`\n",
    "\n",
    "#### Let's create the geodataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b414b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrhd = gpd.GeoDataFrame.from_file(\"Toronto_Neighbourhoods.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd79694",
   "metadata": {},
   "source": [
    "#### Now let's simplify the geodataframe and convert our spatial id from a string to a number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f316cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get gdf ready\n",
    "important_spat_cols = nbrhd.columns[[4, 5, 17]]\n",
    "colnames_spat = {important_spat_cols[0]: 'name',\n",
    "           important_spat_cols[1] : 'nbrhd_spat_id',\n",
    "           important_spat_cols[2] : 'geometry'}\n",
    "\n",
    "#copy the gdf to a new gdf variable name\n",
    "nbrhd_simple = nbrhd.copy()\n",
    "\n",
    "#keep only the 'important' columns and then rename them\n",
    "nbrhd_simple = nbrhd_simple[important_spat_cols]\n",
    "nbrhd_simple.rename(columns = colnames_spat, inplace=True)\n",
    "\n",
    "#create a new variable in the nbrhd_simple geodataframe and store the new number\n",
    "#version of the neighbourhood id here\n",
    "nbrhd_simple[\"Neighbid\"] = nbrhd_simple[\"nbrhd_spat_id\"].astype(int)\n",
    "\n",
    "nbrhd_simple.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89598082",
   "metadata": {},
   "source": [
    "#### Next, let's get our table with health information imported and ready to join with our gdf and then simplify the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492f7053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get neighbourhood attribute data ready\n",
    "\n",
    "fname = '1_ahd_neighb_db_ast_hbp_mhv_copd_2007.xls' #file name\n",
    "sname = '1_ahd_neighb_asthma_2007' #sheet name in excel file\n",
    "\n",
    "#store excel sheet with asthma data in a dataframe variable\n",
    "asthma_neighb = pd.read_excel(fname, sheet_name = sname, header = 11)\n",
    "\n",
    "#let's simplify this by only pulling a few relevant columns\n",
    "important_cols = asthma_neighb.columns[[0, 1, 10, 11]]\n",
    "colnames = {important_cols[0]: 'Neighbid', \n",
    "            important_cols[1] : 'name', \n",
    "            important_cols[2] : 'adult_pop',\n",
    "            important_cols[3] : 'asthma_pct'}\n",
    "\n",
    "asthma_rates = asthma_neighb.copy()\n",
    "\n",
    "asthma_rates = asthma_rates[important_cols]\n",
    "\n",
    "asthma_rates.rename(columns = colnames, inplace=True)\n",
    "\n",
    "asthma_rates.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18642c7f",
   "metadata": {},
   "source": [
    "#### Finally, let's join our neighbourhood gdf with our asthma rate df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4573ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's do the join!\n",
    "nbrhd_simple = nbrhd_simple.merge(asthma_rates, on=\"Neighbid\")\n",
    "nbrhd_simple.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9814af",
   "metadata": {},
   "source": [
    "#### Then let's make sure we can map it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c59c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first let's create a figure variable \"fig\" and an axes variables called \"ax\".\n",
    "#this code sets the stage - it says how many images - by rows/columns, and we can set other\n",
    "#figure attributes in here, like figure size using figsize\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize = (12,12))\n",
    "\n",
    "nbrhd_simple.plot(column='asthma_pct', scheme='quantiles', \n",
    "                  k=5, cmap='YlGn', edgecolor='grey', \n",
    "                  ax = axes, legend=True, \n",
    "                  legend_kwds={'loc': 4, 'title': 'Percent Asthmatic', \n",
    "                               'title_fontsize': 16,'fontsize': 12})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720ffa9b",
   "metadata": {},
   "source": [
    "#### OK, now make a figure with two maps side by side..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a8e79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize = (12,12))\n",
    "\n",
    "# pick the first cell in the figure\n",
    "nbrhd_simple.plot(column = \"name_x\",\n",
    "           ax=axes[0], cmap = \"tab20\")\n",
    "\n",
    "# pick the second cell in the figure\n",
    "nbrhd_simple.plot(column = \"asthma_pct\",\n",
    "           ax=axes[1], cmap = \"YlGn\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8d684f",
   "metadata": {},
   "source": [
    "### POP QUIZ!! \n",
    "\n",
    "1. How would we make a figure with 3 maps in 1 row? \n",
    "2. How would we make a figure with 3 maps in 1 **column**?\n",
    "3. How would we make a figure with 6 maps in 3 rows and 2 columns? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4f86c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(, , figsize = (12,12))\n",
    "\n",
    "nbrhd_simple.plot()\n",
    "nbrhd_simple.plot()\n",
    "nbrhd_simple.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc55e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(, , figsize = (12,12))\n",
    "\n",
    "nbrhd_simple.plot()\n",
    "nbrhd_simple.plot()\n",
    "nbrhd_simple.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90412a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(, , figsize = (12,12))\n",
    "\n",
    "nbrhd_simple.plot()\n",
    "nbrhd_simple.plot()\n",
    "nbrhd_simple.plot()\n",
    "nbrhd_simple.plot()\n",
    "nbrhd_simple.plot()\n",
    "nbrhd_simple.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b0d2e0",
   "metadata": {},
   "source": [
    "# More on Cartography\n",
    "## To this point we have used quantiles to classify values in maps. \n",
    "### What other common options do we have? \n",
    "\n",
    "1. Equal Intervals\n",
    "- This classification method \"divides the data into equal size classes (e.g., 0-10, 10-20, 20-30, etc.) and works best on data that is generally spread across the entire range. CAUTION: Avoid equal interval if your data are skewed to one end or if you have one or two really large outlier values.\"\n",
    "\n",
    "2. Natural Breaks\n",
    "- This classification method \"is a kind of “optimal” classification scheme that finds class breaks that will minimize within-class variance and maximize between-class differences.\" However, these breaks will be unique to each dataset and makes it difficult to compare across different maps. \n",
    "\n",
    "\n",
    "Let's use the `scheme` parameter to the plot our asthma percentages using quartiles, equal intervals, and natural breaks. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e82da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize =  (20,10))\n",
    "\n",
    "nbrhd_simple.plot(column='adult_pop', scheme='quantiles', \n",
    "                  k=4, cmap='YlOrRd', edgecolor='black', \n",
    "                  ax = axes[0], legend=True,                  \n",
    "                  legend_kwds={'loc': 4, 'title': 'Adult Population', \n",
    "                               'title_fontsize': 8,'fontsize': 8})\n",
    "\n",
    "nbrhd_simple.plot(column='adult_pop', scheme='equal_interval', \n",
    "                  k=4, cmap='YlOrRd', edgecolor='black', \n",
    "                  ax = axes[1], legend=True,                  \n",
    "                  legend_kwds={'loc': 4, 'title': 'Adult Population', \n",
    "                               'title_fontsize': 8,'fontsize': 8})\n",
    "\n",
    "nbrhd_simple.plot(column='adult_pop', scheme='natural_breaks', \n",
    "                  k=4, cmap='YlOrRd', edgecolor='black', \n",
    "                  ax = axes[2], legend=True,                  \n",
    "                  legend_kwds={'loc': 4, 'title': 'Adult Population', \n",
    "                               'title_fontsize': 8,'fontsize': 8})\n",
    "\n",
    "axes[0].set_title(\"Quartiles\", fontsize = 20)\n",
    "axes[1].set_title(\"Equal Intervals\", fontsize = 20)\n",
    "axes[2].set_title(\"Natural Breaks\", fontsize = 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3822b20",
   "metadata": {},
   "source": [
    "## Adding a background\n",
    "\n",
    "What if we want to add a background to our maps? It's pretty easy!\n",
    "\n",
    "We will use the contextily library to do this. But first we need to double check that our coordinate reference system is properly set. To layer our maps on top of a web background map, we need to make sure the projection is set to something known as \"Web Mercator\": https://epsg.io/3857\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f35fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check current crs\n",
    "nbrhd_simple.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4365ec92",
   "metadata": {},
   "source": [
    "#### Let's reproject the map into Web Mercator and compare to the original projection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b6f67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrhd_webmap = nbrhd_simple.to_crs(\"EPSG:3857\")\n",
    "\n",
    "#let's throw in a polar projection just for fun! \n",
    "## https://www.esri.com/arcgis-blog/products/imagery/imagery/two-views-from-the-top-of-the-world/\n",
    "nbrhd_polar = nbrhd_simple.to_crs(\"EPSG:3995\")\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize =  (20,10))\n",
    "\n",
    "#original\n",
    "nbrhd_simple.plot(ax = axes[0])\n",
    "#web mercator\n",
    "nbrhd_webmap.plot(ax = axes[1])\n",
    "#polar projection\n",
    "nbrhd_polar.plot(ax = axes[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02942aa0",
   "metadata": {},
   "source": [
    "### To add the web basemap, we can do the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6c8a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha parameter makes the map transparent\n",
    "fig, axes = plt.subplots(1,1, figsize = (10,10))\n",
    "\n",
    "nbrhd_webmap.plot(column = \"asthma_pct\", scheme = \"quantiles\",\n",
    "                  k = 4, cmap = \"Reds\", ax = axes,\n",
    "                  alpha=0.5, edgecolor='k')\n",
    "\n",
    "cx.add_basemap(axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28bd0b5",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "## What is clustering? \n",
    "\n",
    "Clustering, generally, is the act of grouping similar things with eachother. We can do this with non-spatial data as well as spatial data. One common clustering method is k-means, which we won't cover in this class, but if you're interested, there's a nice tutorial on the method here: \n",
    "\n",
    "https://towardsdatascience.com/machine-learning-algorithms-part-9-k-means-example-in-python-f2ad05ed5203\n",
    "\n",
    "\n",
    "## Why do we want to identify clusters? \n",
    "\n",
    "Because clusters identify groups of data with similar attribute values, we can use it to begin to understand what **drives** the grouping. \n",
    "\n",
    "For example, we may have data on individuals' income outcomes and education levels (e.g., total number of years in schools, colleges, and universities). If we perform a cluster analysis, we can identify discrete groups which may be easier to work with when we want to do further analysis. These groups may be something like:\n",
    "\n",
    " - cluster 1: high income, more education\n",
    " - cluster 2: high income, less education\n",
    " - cluster 3: low income, less education\n",
    " - cluster 4: low income, more education\n",
    " \n",
    "From there, we can look at other attributes of those clusters. This approach is commonly used in demographic analysis where many attributes are considered to create discrete clusters. A good example of this used in practice is Environics Analytics PRIZM Segmentation:\n",
    "\n",
    "https://environicsanalytics.com/en-ca/data/segmentation\n",
    "\n",
    "![example of different segments](https://environicsanalytics.com/images/default-source/product-pages/page-content/prizm-page-illustrations-cards.png)\n",
    "\n",
    "[You can look up what 'demographic segment' or cluster your postal code belongs to here!](https://prizm.environicsanalytics.com/?_ga=2.84764121.114697395.1648300904-78433696.1648300904)\n",
    "\n",
    "### Spatial clustering, at a high level, is doing the same thing but one attribute to consider is geography. \n",
    "\n",
    "Spatial clustering involves looking at how some attribute is expressed across space and whether similar attribute values are near eachother. \n",
    "\n",
    "#### If we want to do 'spatial clustering' of a variable what two pieces of information do we need? (don't over think!!!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7256fb2b",
   "metadata": {},
   "source": [
    "## Autocorrelation\n",
    "\n",
    "Autocorrelation literally means 'self correlations'. So instead of looking at how two attributes relate to eachother, we want to explore one a single attribute relates to its neighbours.\n",
    "\n",
    "Typically, we're talking about temporal autocorrelation or spatial autocorrelation.\n",
    "\n",
    "## Spatial Autocorrelation\n",
    "\n",
    "How does a variable value in a specific location correlate with the variable values in its neighbours? \n",
    "\n",
    "#### So again, information do we need to do answer this question?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4ab2e6",
   "metadata": {},
   "source": [
    "### 1) For each observation (in this case, neighborhood) we need to know their neighbours!\n",
    "\n",
    "To do this we can create something known as a 'weights matrix'.\n",
    "\n",
    "A weights matrix is a matrix that describes whether or not any one observation is 'neighbours' with another.\n",
    "\n",
    "There are many ways we can do this, but let's focus on two common ones: queens contiguity matrix and the rook contiguity matrix:\n",
    "\n",
    "![weights matrices](https://i.stack.imgur.com/CWIHi.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ac575d",
   "metadata": {},
   "source": [
    "### 2) Next we need to describe the value of our attribute of interest in neighbours\n",
    "\n",
    "To do this we create a variable known as 'spatial lag'. Spatial lag for neighbourhood i is often just the average of some attribute value across all of neighbourhood i's neighbours (as determined by our weights matrix!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4876a88a",
   "metadata": {},
   "source": [
    "### 3) Finally, now we can see how a neighbourhood's attribute compares to its neighbours. \n",
    "\n",
    "This set up allows us to see if neighbourhood's with high attribute values are next to other neighbourhoods with high values. We can then use a number of statistical tests to determine if there are 'significant' clusters in our dataset. \n",
    "\n",
    "### Let's move to some code to show how all this works.\n",
    "\n",
    "Let's see if we have spatial clusters in:\n",
    "1. the percent of adults with asthma in Toronto\n",
    "2. a random column of numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839ed941",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Before we get going I'm going to add a column of random numbers to our nbrhd_simple gdf. \n",
    "#I'm doing this to generate a random spatial pattern in our toronto dataset. We shouldn't expect\n",
    "#any spatial clusters in this random data\n",
    "nbrhd_simple['randNumCol'] = np.random.randint(1, 101, nbrhd_simple.shape[0])\n",
    "nbrhd_simple.plot(column = \"randNumCol\", cmap = 'YlOrRd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92976039",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display \n",
    "# Supress warnings because of an annoying projections issue:\n",
    "\n",
    "# Create the spatial weights matrix\n",
    "w = lps.weights.Queen.from_dataframe(nbrhd_simple)\n",
    "\n",
    "fig, axes = plt.subplots(1,1, figsize = (12,12))\n",
    "\n",
    "# add nbrhd map\n",
    "nbrhd_simple.plot(ax = axes)\n",
    "\n",
    "# show what weights look like\n",
    "w.plot(nbrhd_simple, ax=axes, \n",
    "        edge_kws=dict(color='r', linewidth=1),\n",
    "        node_kws=dict(marker=''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe707b45",
   "metadata": {},
   "source": [
    "### Let's inspect the weights matrix further. What does it look like: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d2ff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "w[0] # the first location has 5 neighbours: 128, 1, 133, 134, and 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbe7895",
   "metadata": {},
   "outputs": [],
   "source": [
    "w[128] #let's see if 128 is also connected to 0..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ff16d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can also look at the distribution of connections using the built in weights histogram function.\n",
    "# the first number is the count of connections and the second number is the number of neighbourhoods with\n",
    "# this count of connections. For example, there are 9 nbrhds with 3 connections, 13 with 4 connections, etc.\n",
    "w.histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c123ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally let's 'row standardize' our matrix so that each nbrhd's connections sum to one:\n",
    "# Row standardize the matrix\n",
    "w.transform = 'R'\n",
    "\n",
    "#how did this change things?\n",
    "print('weights for nbrhd 0: ', w[0])\n",
    "print('weights for nbrhd 128: ', w[128])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d107502",
   "metadata": {},
   "source": [
    "### Now that we have spatial weights established, we can calculate spatial lag.\n",
    "\n",
    "Let's do that for asthma_pct and for randNumCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c78a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the average of asthma_pct attribute of neighbours, then store in a new column\n",
    "nbrhd_simple['w_asthma_pct'] = lps.weights.lag_spatial(w, nbrhd_simple['asthma_pct'])\n",
    "nbrhd_simple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f383fa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look at a scatter plot between asthma_pct in each neighbourhood vs. the avg asthma_pct in their neighbors\n",
    "nbrhd_simple.plot.scatter(x = \"asthma_pct\", y = \"w_asthma_pct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c682ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's repeat the above, but for our random number column we created.\n",
    "nbrhd_simple['w_randNumCol'] = lps.weights.lag_spatial(w, nbrhd_simple['randNumCol'])\n",
    "nbrhd_simple.plot.scatter(x = \"randNumCol\", y = \"w_randNumCol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586eabed",
   "metadata": {},
   "source": [
    "## So what do we see in the above two scatterplots?\n",
    "\n",
    "#### Prompt:\n",
    "As 'asthma_pct' in a specific neighbourhood gets larger, the average value of 'asthma_pct' in that neighbhourhood's neighbours *(gets smaller/gets bigger/doesn't change)*.\n",
    "\n",
    "#### Prompt: \n",
    "As 'randNumCol' in a specific neighbourhood gets larger, the average value of 'randNumCol' in that neighbhourhood's neighbours *(gets smaller/gets bigger/doesn't change)*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499f30f6",
   "metadata": {},
   "source": [
    "## Moran's I\n",
    "Moran's I is global spatial autocorrelation statistic that tells us if high values are next to high values and low values are next to low values. There is also a way to determine if this occurs at a significan level - e.g., does this sorting happen more than expected if the values were randomly spread across our study area.\n",
    "\n",
    "The value of Moran's I ranges from -1 to 1, where I of 1 is perfectly clustered and -1 is perfectly 'dispersed'\n",
    "\n",
    "![example of morans I](https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20200421144010724-0711:9781108614528:49898fig4_1.png)\n",
    "\n",
    "**Ho = the values of asthma_pct are randomly distributed across our study area**\n",
    "\n",
    "**Ha = the values of asthma_pct are not randomly distributed (aka we have spatial clusters in our study area)** \n",
    "\n",
    "If our p value is < 0.05 we will reject our null hypothesis Ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc6784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from splot.esda import moran_scatterplot\n",
    "\n",
    "mi = esda.Moran(nbrhd_simple['asthma_pct'], w)\n",
    "\n",
    "print('The Morans I value is: ', mi.I)\n",
    "print('The p-value of this Morans I value is: ', mi.p_sim)\n",
    "\n",
    "#visualize!\n",
    "splot.esda.moran_scatterplot(mi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6fd316",
   "metadata": {},
   "source": [
    "The Moran's plot shows us the same scatter we saw before except now they've standardized the variable value and the spatial lag values (aka made them z-scores, where 0 is average). \n",
    "\n",
    "We can break the scatterplot into 4 quadrants - going counter clockwise, starting from the upper-right. \n",
    "\n",
    "1. The upper right is the 'high-high' quadrant, where high values in a nbrhd are next to neighbours with high values (quadrant 1)\n",
    "2. The upper left is the 'low-high' quadrant, where low values in a nbrhd are next to neighbours with high values (quadrant 2)\n",
    "3. The lower left is the 'low-low' quadrant (quadrant 3)\n",
    "4. The lower right is the 'high-low' quadrant (quadrant 4)\n",
    "\n",
    "\n",
    "If most points in our scatterplot are in the high-high and low-low quadrants we probably have clustering. If they are mostly in the low-high and high-low then there's likely dispersal. If there is no obvious pattern, then there's probably no clustering!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2911ec6c",
   "metadata": {},
   "source": [
    "### Let's do it again with the random numbers column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b540218",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_randNumCol = esda.Moran(nbrhd_simple['randNumCol'], w)\n",
    "\n",
    "print('The Morans I value is: ', mi_randNumCol.I)\n",
    "print('The p-value of this Morans I value is: ', mi_randNumCol.p_sim)\n",
    "\n",
    "#visualize!\n",
    "splot.esda.moran_scatterplot(mi_randNumCol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb40fec",
   "metadata": {},
   "source": [
    "## Local Spatial Autocorrelation\n",
    "\n",
    "### OK, that's great, but WHERE are the clusters? \n",
    "\n",
    "We can use a different statistic to identify significant incidents of local spatial autocorrelation. This tells us exactly where on the map this clustering is happening!\n",
    "\n",
    "We can think about the Moran's I plots to help us here. Using a new function we can identify which quadrant each neighbourhood is in, and if the relationship to neighbourhing values is strong enough to be significant. \n",
    "\n",
    "Those observations in quadrant 1 and 3 are 'clustered' and those in 2 and 4 would be 'outliers'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ac2718",
   "metadata": {},
   "outputs": [],
   "source": [
    "lisa = esda.Moran_Local(nbrhd_simple['asthma_pct'], w)\n",
    "# Break observations into significant or not\n",
    "nbrhd_simple['significant'] = lisa.p_sim < 0.05\n",
    "# Store the quadrant they belong to\n",
    "nbrhd_simple['quadrant'] = lisa.q\n",
    "nbrhd_simple[['asthma_pct','w_asthma_pct','significant','quadrant']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bb0188",
   "metadata": {},
   "source": [
    "### We can use a built in function to plot the results, but this map is kind of ugly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc61093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from splot.esda import lisa_cluster\n",
    "splot.esda.lisa_cluster(lisa, nbrhd_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17954c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the figure and axis\n",
    "fig, axes = plt.subplots(1,1, figsize=(12, 12))\n",
    "\n",
    "# Plot insignificant clusters\n",
    "ns = nbrhd_simple.loc[nbrhd_simple['significant']==False, 'geometry']\n",
    "ns.plot(ax=axes, color='white', edgecolor='grey')\n",
    "\n",
    "# Plot HH clusters\n",
    "hh = nbrhd_simple.loc[(nbrhd_simple['quadrant']==1) & (nbrhd_simple['significant']==True), 'geometry']\n",
    "hh.plot(ax=axes, color='red', edgecolor='grey')\n",
    "\n",
    "# Plot LL clusters\n",
    "ll = nbrhd_simple.loc[(nbrhd_simple['quadrant']==3) & (nbrhd_simple['significant']==True), 'geometry']\n",
    "ll.plot(ax=axes, color='blue', edgecolor='grey')\n",
    "\n",
    "# Plot LH clusters\n",
    "lh = nbrhd_simple.loc[(nbrhd_simple['quadrant']==2) & (nbrhd_simple['significant']==True), 'geometry']\n",
    "lh.plot(ax=axes, color='lightblue', edgecolor='grey')\n",
    "\n",
    "# Plot HL clusters\n",
    "hl = nbrhd_simple.loc[(nbrhd_simple['quadrant']==4) & (nbrhd_simple['significant']==True), 'geometry']\n",
    "hl.plot(ax=axes, color='salmon', edgecolor='grey')\n",
    "\n",
    "\n",
    "# Style and draw\n",
    "axes.set_title(\"Adult Asthma Percentages\", fontsize = 23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123eeb9d",
   "metadata": {},
   "source": [
    "## Finally, one more built in plot if you want!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cd9019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from splot.esda import plot_local_autocorrelation\n",
    "splot.esda.plot_local_autocorrelation(lisa, nbrhd_simple, 'asthma_pct')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ef9e90",
   "metadata": {},
   "source": [
    "## Finally finally, let's look at what the random number col looks like..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0229d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "lisa_randNumCol = esda.Moran_Local(nbrhd_simple['randNumCol'], w)\n",
    "splot.esda.plot_local_autocorrelation(lisa_randNumCol, nbrhd_simple, 'randNumCol')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed2bf44",
   "metadata": {},
   "source": [
    "### What's up with that!!! \n",
    "\n",
    "Even random distributions of data across space will sometime generate local clusters.\n",
    "\n",
    "It's always good to consider the GLOBAL and LOCAL measures of spatial autocorrelation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10687d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
